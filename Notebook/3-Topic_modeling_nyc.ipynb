{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad6e77dc-e721-4033-8e01-ec9d8c7849d3",
   "metadata": {},
   "source": [
    "**In this notebook, we perform topic modeling on a dataset of English hotel reviews from New York City. The process involves several key steps:**\n",
    "\n",
    "**Text Preprocessing: We begin by cleaning and preprocessing the text data, including tokenization, stopword removal, and lemmatization, to prepare it for analysis.**\n",
    "\n",
    "**Topic Modeling: Using the BERTopic framework, we apply dimensionality reduction, clustering, and topic extraction techniques to identify distinct topics within the reviews. The model identifies themes such as overall hotel experience, service issues, room cleanliness, noise levels, and specific amenities.**\n",
    "\n",
    "**Visualization: The notebook includes visualizations to explore the distribution of topics, the relationships between them, and the most representative words for each topic.**\n",
    "\n",
    "**Topic Mapping and Analysis: We map the identified topics to labels for easier interpretation and analyze the distribution of these topics across the dataset. The labeled topics are then used to further explore trends and patterns within the reviews, including filtering for negative sentiments.**\n",
    "\n",
    "**The results are saved for subsequent analysis and interpretation, providing valuable insights into customer experiences and perceptions of hotels in New York City.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc01fb6-b9ad-4e67-842d-4c1f9ad2a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add67bab-5013-4ddc-9029-fe891342f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.version.cuda)  # Check the CUDA version PyTorch is using\n",
    "print(torch.backends.cudnn.enabled)  # Check if cuDNN is enabled\n",
    "print(torch.cuda.is_available())  # Should return True if everything is set up correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1a890-a412-41a7-9dc9-19485128279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='tqdm')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='huggingface_hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e9f72-8bfa-4c86-843b-59209071a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Python version:\", sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76356391-27ba-4f14-839d-68a12a7f3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f74bb-62a6-4ddb-a6df-aa5dc13a1c6f",
   "metadata": {},
   "source": [
    "## Preprocess the Text Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced9d3c-d1d5-49b5-ada6-c26bde9e2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/eng_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb51f50-2f68-448c-a9d5-d3342ed3154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'punkt', 'stopwords', and 'wordnet' are already downloaded\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52b42e-ecaf-4f7d-8e77-49d1c30deede",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df['name'].unique()\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Add domain-specific stop words\n",
    "domain_stop_words = set(ENGLISH_STOP_WORDS).union({'hotel', 'stay', 'hotels', 'night', 'timesquare', 'times', 'square', 'hilton', \n",
    "                                                   'new', 'york', 'nyc', 'day', 'stayed', 'just', 'really', 'stay'\n",
    "                                                   'amazing', 'awesome', 'best', 'better', 'excellent', 'fantastic', 'horrible', 'rooms', 'room', 'great', 'bad',\n",
    "                                                   'perfect', 'poor', 'terrible', 'wonderful', 'awful', 'nice', 'okay', 'mediocre', 'good',\n",
    "                                                   'superb', 'lousy', 'disappointing', 'satisfactory', 'decent', 'pleasant', \n",
    "                                                   'unpleasant', 'memorable', 'forgettable', 'unremarkable'})\n",
    "# Convert names list to a set and merge with domain_stop_words\n",
    "domain_stop_words = domain_stop_words.union(set(names))\n",
    "\n",
    "domain_stop_words = list(domain_stop_words)\n",
    "\n",
    "# Preprocess the text data again with the updated stop words\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in domain_stop_words]\n",
    "    return ' '.join(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7200d21-f0db-468f-bafa-021760476639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to the 'cleaned_text' column\n",
    "df['processed_text'] = df['cleaned_text'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the processed data\n",
    "print(df[['cleaned_text', 'processed_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e8666f-801b-4a85-b730-75deeaee20f7",
   "metadata": {},
   "source": [
    "## Apply Topic Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fcad0a-bbb5-4270-be58-f8f661f84ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Pre-calculate embeddings\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', trust_remote_code=True).to(device)\n",
    "# SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# SentenceTransformer('Alibaba-NLP/gte-large-en-v1.5', trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7529e6-12e4-478e-98e3-12a14e0776e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentences\n",
    "embeddings = embedding_model.encode(df['processed_text'], show_progress_bar=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40d132-1f21-4ea7-85cd-9bf7425355c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap_model = UMAP(n_neighbors=20\n",
    "                  , n_components=3, min_dist=0.0, metric='cosine', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7b8f1-9833-445e-873a-3db3f69bc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=150, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454bdba-fda8-4893-ad01-032b7fbc8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words=domain_stop_words, min_df=10, ngram_range=(1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c61b87-d6cf-480f-b374-8f89d4ba1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance\n",
    "\n",
    "\n",
    "# KeyBERT\n",
    "keybert_model = KeyBERTInspired()\n",
    "\n",
    "# MMR\n",
    "mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "# All representation models\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert_model,\n",
    "    # \"OpenAI\": openai_model,  # Uncomment if you will use OpenAI\n",
    "    \"MMR\": mmr_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6d373-087f-4fd6-9d84-018e212135c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48a097-3156-4050-ae74-19e986a18aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the BERTopic model\n",
    "\n",
    "topic_model = BERTopic(\n",
    "\n",
    "  # Pipeline models\n",
    "  embedding_model=embedding_model,\n",
    "  umap_model=umap_model,\n",
    "  hdbscan_model=hdbscan_model,\n",
    "  vectorizer_model=vectorizer_model,\n",
    "  representation_model=representation_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  nr_topics=20,\n",
    "  verbose=True\n",
    "\n",
    ")\n",
    "\n",
    "# Train model\n",
    "topics, probs = topic_model.fit_transform(df['processed_text'], embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83aea9-107e-4fa0-8562-57e1729febe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the topics\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c809203-de68-44c7-8ce0-9d74489ad4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize UMAP projection and HDBSCAN clustering\n",
    "topic_model.visualize_documents(df['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ba96d-3da1-4bba-bc8a-8a5e604ac665",
   "metadata": {},
   "source": [
    "## Visualize Topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e69f3-0d2a-4d68-8f01-8390a06f9586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b96eec0-ba44-4cf4-a55f-27f8fa87e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c27e12-a2a5-432f-b1a8-969da7105a12",
   "metadata": {},
   "source": [
    "## Analyze Topic Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2f576-07c0-4f37-a523-8df3c4844b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the topic results to the DataFrame\n",
    "df['topic'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b134bd5-c62b-4bf7-8040-15679dc36fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distribution of topics\n",
    "topic_distribution = df['topic'].value_counts()\n",
    "print(topic_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc91f70-d7c3-4ed2-bb21-47ca34b06747",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_distribution(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c353c5-b9f3-45e7-b75a-fe7dc671d102",
   "metadata": {},
   "source": [
    "## Examine Top Words per Topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948df2d2-59c6-438a-9695-42cac0dff40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract topic information\n",
    "topic_info = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141035f-7408-4f4e-bbe5-c913cbe2df97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the top words for each topic\n",
    "for topic_id in topic_info['Topic']:\n",
    "    if topic_id != -1:  # -1 is the outlier/noise topic\n",
    "        print(f\"Topic {topic_id}: {topic_model.get_topic(topic_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cf72f-1ae8-446b-a419-3fcd27514334",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics = topic_model.reduce_outliers(df['processed_text'], topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9419122-13f1-4832-8283-e98aec2c8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_topics'] = new_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fc41a-2e5a-4184-b6cc-693244a1e191",
   "metadata": {},
   "source": [
    "# Topic Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0a55c-ba04-49e7-975b-09e1cf10d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels based on the topics\n",
    "topic_labels = {\n",
    "    0: \"Overall Hotel Experience\",\n",
    "    1: \"Front Desk and Service Issues\",\n",
    "    2: \"Positive Experience: Location and Staff\",\n",
    "    3: \"Comfort and Cleanliness of Rooms\",\n",
    "    4: \"Noise and Sleep Quality\",\n",
    "    5: \"Specific Hotel Chains and Suites\",\n",
    "    6: \"Breakfast and Additional Amenities\",\n",
    "    7: \"Hotel Names and Wine & Cheese Offerings\",\n",
    "    8: \"WiFi and Internet Services\",\n",
    "    9: \"Natural Disasters and Staff Response\",\n",
    "    10: \"Hotel Names and Room Conditions\",\n",
    "    11: \"Evening Offerings: Wine, Cheese, and Breakfast\",\n",
    "    12: \"Hotel Pennsylvania and Room Conditions\",\n",
    "    13: \"Bed Bug Issues\",\n",
    "    14: \"Hotel Muse and Kimpton Properties\",\n",
    "    15: \"Elevator Issues\",\n",
    "    16: \"Service and Small Room Size\",\n",
    "    17: \"Overall Hotel Atmosphere\",\n",
    "    18: \"Room Amenities: Microwave and Fridge\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b3e67-fa3e-4113-96a5-91117dc1cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the labels to a new column in the DataFrame\n",
    "df['label'] = df['new_topics'].map(topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03c6b8-d46a-412e-9459-c7f8b80e9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only include rows where the sentiment is negative\n",
    "negative_sentiment_df = df[df['sentiment'] == 'NEGATIVE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67ab62-d286-4787-914a-f798f6d07389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_with_topics.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
